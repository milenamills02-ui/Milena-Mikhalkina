{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "Прогнозирование кредитного дефолта\n",
    "В работе реализован полный цикл: анализ данных, предобработка, создание признаков, обучение моделей и реализация собственной логистической регрессии.\n",
    "Задача — предсказать Credit Default (1 — дефолт, 0 — нет).\n",
    "Метрика — F1-score для класса 1, по условию она должна быть больше 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec0",
   "metadata": {},
   "source": [
    "0. Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style('whitegrid')\n",
    "RANDOM_STATE = 42\n",
    "print('Импорты выполнены успешно')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec1",
   "metadata": {},
   "source": [
    "1. EDA — Разведочный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('course_project_train.csv')\n",
    "test  = pd.read_csv('course_project_test.csv')\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_info",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Типы данных и пропуски ===')\n",
    "info = pd.DataFrame({\n",
    "    'dtype':   train.dtypes,\n",
    "    'nulls':   train.isnull().sum(),\n",
    "    'null_%':  (train.isnull().sum() / len(train) * 100).round(2)\n",
    "})\n",
    "display(info)\n",
    "print('\\n=== Статистика числовых признаков ===')\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение целевой переменной\n",
    "counts = train['Credit Default'].value_counts()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].bar(['Нет дефолта (0)', 'Дефолт (1)'], counts.values, color=['steelblue', 'tomato'])\n",
    "axes[0].set_title('Распределение целевой переменной')\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(i, v + 30, str(v), ha='center', fontweight='bold')\n",
    "axes[1].pie(counts.values, labels=['Нет дефолта (0)', 'Дефолт (1)'],\n",
    "            autopct='%1.1f%%', colors=['steelblue', 'tomato'])\n",
    "axes[1].set_title('Доля классов')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f'Дисбаланс: {counts[0]} vs {counts[1]} = {counts[0]/counts[1]:.2f}:1')\n",
    "print('→ Необходима балансировка классов!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_outlier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выброс в Current Loan Amount\n",
    "print('Значения Current Loan Amount = 99999999:', (train['Current Loan Amount'] == 99999999).sum())\n",
    "print('→ Это sentinel-значение (not a number), заменяем на NaN')\n",
    "\n",
    "# Credit Score\n",
    "cs = train['Credit Score'].dropna()\n",
    "print(f'\\nCredit Score: min={cs.min()}, max={cs.max()}, mean={cs.mean():.0f}')\n",
    "print(f'Значения > 850: {(cs > 850).sum()} шт.')\n",
    "print('→ Датасет использует нестандартную шкалу кредитного рейтинга.')\n",
    "print('  Нормировка деления на 10 была проверена и ухудшила F1 — оставляем как есть.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределения числовых признаков\n",
    "num_cols = train.select_dtypes(include=np.number).columns.drop('Credit Default')\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 11))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(num_cols):\n",
    "    train[col].hist(ax=axes[i], bins=40, color='steelblue', edgecolor='white')\n",
    "    axes[i].set_title(col)\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "plt.suptitle('Распределения числовых признаков', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_cat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Категориальные признаки vs целевая переменная\n",
    "cat_cols = ['Home Ownership', 'Purpose', 'Term']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    default_rate = train.groupby(col)['Credit Default'].mean().sort_values(ascending=False)\n",
    "    default_rate.plot(kind='bar', ax=axes[i], color='tomato', edgecolor='white')\n",
    "    axes[i].set_title(f'Доля дефолта по {col}')\n",
    "    axes[i].set_ylabel('Доля дефолтов')\n",
    "    axes[i].tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_corr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr = train[num_cols.tolist() + ['Credit Default']].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Корреляционная матрица числовых признаков')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec2",
   "metadata": {},
   "source": [
    "2. Категории закодированы через get_dummies, потом те же преобразования применены к тесту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raw_prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_MAP = {\n",
    "    '< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,\n",
    "    '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9,\n",
    "    '10+ years': 11\n",
    "}\n",
    "\n",
    "def raw_prepare(df):\n",
    "    \"\"\"Базовая подготовка: выбросы + порядковый признак + One-Hot Encoding.\"\"\"\n",
    "    df = df.copy()\n",
    "    # 1. Выброс-sentinel\n",
    "    df['Current Loan Amount'] = df['Current Loan Amount'].replace(99999999, np.nan)\n",
    "    # 2. Порядковый признак\n",
    "    df['Years in current job'] = df['Years in current job'].map(YEARS_MAP)\n",
    "    # 3. Бинарный признак Term\n",
    "    df['Term_Long'] = (df['Term'] == 'Long Term').astype(int)\n",
    "    df.drop('Term', axis=1, inplace=True)\n",
    "    # 4. One-Hot Encoding (drop_first убирает мультиколлинеарность)\n",
    "    df = pd.get_dummies(df, columns=['Home Ownership', 'Purpose'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "TARGET = 'Credit Default'\n",
    "train_raw = raw_prepare(train)\n",
    "test_raw  = raw_prepare(test)\n",
    "\n",
    "# Выравниваем колонки test по train (на случай разных категорий)\n",
    "feature_cols = [c for c in train_raw.columns if c != TARGET]\n",
    "test_raw = test_raw.reindex(columns=feature_cols, fill_value=0)\n",
    "\n",
    "X_raw      = train_raw.drop(TARGET, axis=1)\n",
    "y          = train_raw[TARGET]\n",
    "X_test_raw = test_raw.copy()\n",
    "\n",
    "print('Признаков после кодирования:', X_raw.shape[1])\n",
    "print('Пропуски в X_raw:', X_raw.isnull().sum().sum())\n",
    "print('→ Пропуски остались: заполним внутри Pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec3",
   "metadata": {},
   "source": [
    "3. sklearn Pipeline \n",
    "Эти шаги собраны в Pipeline, чтобы не повторять код и чтобы всё применялось одинаково при обучении и проверке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transformers",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Заполняет пропуски:\n",
    "    - числовые признаки → медиана (вычислена на fit)\n",
    "    - Bankruptcies, Tax Liens → 0 (отсутствие = нет событий)\n",
    "    \"\"\"\n",
    "    ZERO_FILL = ['Bankruptcies', 'Tax Liens']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X\n",
    "        # Медианы по всем числовым (кроме zero-fill)\n",
    "        self.medians_ = X.drop(columns=[c for c in self.ZERO_FILL if c in X.columns],\n",
    "                                errors='ignore').median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = (pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X).copy()\n",
    "        # Zero-fill\n",
    "        for col in self.ZERO_FILL:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna(0)\n",
    "        # Median-fill\n",
    "        X = X.fillna(self.medians_)\n",
    "        return X\n",
    "\n",
    "\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Генерация новых признаков из существующих:\n",
    "    - Debt_to_Income     : долговая нагрузка / доход\n",
    "    - Credit_Utilization : использование кредитного лимита\n",
    "    - Debt_per_Account   : долг на один открытый счёт\n",
    "    - Has_Delinquent     : флаг наличия факта просрочки\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # stateless\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = (pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X).copy()\n",
    "        X['Debt_to_Income']     = X['Monthly Debt'] * 12 / (X['Annual Income'] + 1)\n",
    "        X['Credit_Utilization'] = X['Current Credit Balance'] / (X['Maximum Open Credit'] + 1)\n",
    "        X['Debt_per_Account']   = X['Monthly Debt'] / (X['Number of Open Accounts'] + 1)\n",
    "        X['Has_Delinquent']     = (X['Months since last delinquent'] < 999).astype(int)\n",
    "        return X\n",
    "\n",
    "print('Кастомные трансформеры определены: MissingValueImputer, FeatureEngineer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec4",
   "metadata": {},
   "source": [
    "4. Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_raw, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(f'Train: {X_train.shape} | Val: {X_val.shape}')\n",
    "print(f'Баланс классов в train: {y_train.value_counts().to_dict()}')\n",
    "\n",
    "THRESHOLDS = np.arange(0.20, 0.70, 0.02)\n",
    "\n",
    "def best_f1_with_threshold(model, X_val, y_val):\n",
    "    \"\"\"Перебирает пороги и возвращает лучший F1 и порог.\"\"\"\n",
    "    proba = model.predict_proba(X_val)[:, 1]\n",
    "    f1s   = [f1_score(y_val, (proba >= t).astype(int)) for t in THRESHOLDS]\n",
    "    best_idx = int(np.argmax(f1s))\n",
    "    return max(f1s), THRESHOLDS[best_idx], proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipe_lr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Baseline: Logistic Regression (sklearn) ──────────────────────────────────\n",
    "pipe_lr = Pipeline([\n",
    "    ('imputer', MissingValueImputer()),\n",
    "    ('fe',      FeatureEngineer()),\n",
    "    ('scaler',  StandardScaler()),\n",
    "    ('model',   LogisticRegression(\n",
    "        class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "f1_lr, thr_lr, _ = best_f1_with_threshold(pipe_lr, X_val, y_val)\n",
    "\n",
    "print('=== Baseline: Logistic Regression (sklearn Pipeline) ===')\n",
    "print(f'F1-score: {f1_lr:.4f}  |  порог: {thr_lr:.2f}')\n",
    "proba_lr = pipe_lr.predict_proba(X_val)[:, 1]\n",
    "print(classification_report(y_val, (proba_lr >= thr_lr).astype(int),\n",
    "                             target_names=['Нет дефолта', 'Дефолт']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipe_rf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Random Forest Pipeline ────────────────────────────────────────────────────\n",
    "pipe_rf = Pipeline([\n",
    "    ('imputer', MissingValueImputer()),\n",
    "    ('fe',      FeatureEngineer()),\n",
    "    ('model',   RandomForestClassifier(\n",
    "        n_estimators=300, class_weight='balanced',\n",
    "        max_depth=10, min_samples_leaf=5,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "f1_rf, thr_rf, proba_rf = best_f1_with_threshold(pipe_rf, X_val, y_val)\n",
    "\n",
    "print('=== Random Forest Pipeline ===')\n",
    "print(f'F1-score: {f1_rf:.4f}  |  порог: {thr_rf:.2f}')\n",
    "print(classification_report(y_val, (proba_rf >= thr_rf).astype(int),\n",
    "                             target_names=['Нет дефолта', 'Дефолт']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipe_gb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Gradient Boosting Pipeline ────────────────────────────────────────────────\n",
    "cw  = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "sw  = np.where(y_train == 1, cw[1], cw[0])\n",
    "\n",
    "pipe_gb = Pipeline([\n",
    "    ('imputer', MissingValueImputer()),\n",
    "    ('fe',      FeatureEngineer()),\n",
    "    ('model',   GradientBoostingClassifier(\n",
    "        n_estimators=200, learning_rate=0.1,\n",
    "        max_depth=5, subsample=0.8,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "pipe_gb.fit(X_train, y_train, model__sample_weight=sw)\n",
    "f1_gb, thr_gb, proba_gb = best_f1_with_threshold(pipe_gb, X_val, y_val)\n",
    "\n",
    "print('=== Gradient Boosting Pipeline ===')\n",
    "print(f'F1-score: {f1_gb:.4f}  |  порог: {thr_gb:.2f}')\n",
    "print(classification_report(y_val, (proba_gb >= thr_gb).astype(int),\n",
    "                             target_names=['Нет дефолта', 'Дефолт']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threshold_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор порога — визуализация для лучшей модели (Random Forest)\n",
    "f1_by_thr = [f1_score(y_val, (proba_rf >= t).astype(int)) for t in THRESHOLDS]\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.plot(THRESHOLDS, f1_by_thr, marker='o', color='steelblue')\n",
    "plt.axvline(thr_rf, color='red', linestyle='--', label=f'Лучший порог = {thr_rf:.2f}')\n",
    "plt.axhline(0.5, color='grey', linestyle=':', label='Целевой F1 = 0.5')\n",
    "plt.xlabel('Порог вероятности')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score при разных порогах (Random Forest)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crossval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-валидация — Pipeline автоматически применяет трансформации на каждом фолде\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = cross_val_score(pipe_rf, X_raw, y, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print('=== 5-Fold Stratified Cross-Validation (Random Forest Pipeline) ===')\n",
    "print(f'F1 по фолдам: {cv_scores.round(4)}')\n",
    "print(f'Среднее: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion_mat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок для лучшей модели\n",
    "y_pred_rf = (proba_rf >= thr_rf).astype(int)\n",
    "cm = confusion_matrix(y_val, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Нет дефолта', 'Дефолт'],\n",
    "            yticklabels=['Нет дефолта', 'Дефолт'])\n",
    "plt.title(f'Матрица ошибок — Random Forest (порог={thr_rf:.2f})')\n",
    "plt.ylabel('Истинный класс')\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feat_imp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важность признаков (Random Forest)\n",
    "# После Pipeline: imputer → fe → model\n",
    "# Имена признаков берём от FeatureEngineer\n",
    "X_transformed_sample = pipe_rf.named_steps['fe'].transform(\n",
    "    pipe_rf.named_steps['imputer'].transform(X_train)\n",
    ")\n",
    "feature_names = list(X_transformed_sample.columns)\n",
    "fi = pd.Series(\n",
    "    pipe_rf.named_steps['model'].feature_importances_,\n",
    "    index=feature_names\n",
    ").nlargest(15)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "fi.sort_values().plot(kind='barh', color='steelblue')\n",
    "plt.title('Топ-15 важных признаков (Random Forest)')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение моделей\n",
    "results = pd.DataFrame({\n",
    "    'Модель': ['Logistic Regression (sklearn)', 'Random Forest', 'Gradient Boosting'],\n",
    "    'F1-score': [f1_lr, f1_rf, f1_gb],\n",
    "    'Оптимальный порог': [thr_lr, thr_rf, thr_gb]\n",
    "}).sort_values('F1-score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(results)\n",
    "\n",
    "plt.figure(figsize=(9, 3.5))\n",
    "bars = plt.barh(results['Модель'], results['F1-score'],\n",
    "                color=['gold', 'steelblue', 'teal'])\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Цель F1 > 0.5')\n",
    "for bar, val in zip(bars, results['F1-score']):\n",
    "    plt.text(bar.get_width() + 0.003, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.4f}', va='center', fontweight='bold')\n",
    "plt.xlabel('F1-score')\n",
    "plt.title('Сравнение моделей (sklearn Pipeline)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec5",
   "metadata": {},
   "source": [
    "5. Дополнительно реализована собственная версия логистической регрессии на основе градиентного спуска. При обучении учитывался дисбаланс классов через веса выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_lr",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    \"\"\"\n",
    "    Логистическая регрессия, реализованная с нуля.\n",
    "\n",
    "    Параметры:\n",
    "    - lr          : learning rate для SGD\n",
    "    - n_epochs    : число эпох обучения\n",
    "    - batch_size  : размер мини-батча\n",
    "    - lambda_     : коэффициент L2-регуляризации (Ridge)\n",
    "    - class_weight: 'balanced' — автоматическая балансировка классов\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.05, n_epochs=150, batch_size=64,\n",
    "                 lambda_=0.01, class_weight=None, random_state=42):\n",
    "        self.lr           = lr\n",
    "        self.n_epochs     = n_epochs\n",
    "        self.batch_size   = batch_size\n",
    "        self.lambda_      = lambda_\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.losses_      = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Численно стабильная сигмоида.\"\"\"\n",
    "        return np.where(\n",
    "            z >= 0,\n",
    "            1 / (1 + np.exp(-z)),\n",
    "            np.exp(z) / (1 + np.exp(z))\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        X = np.array(X, dtype=np.float64)\n",
    "        y = np.array(y, dtype=np.float64)\n",
    "        n, p = X.shape\n",
    "\n",
    "        # Xavier инициализация\n",
    "        self.weights_ = np.random.randn(p) * np.sqrt(2 / p)\n",
    "        self.bias_    = 0.0\n",
    "\n",
    "        # Балансировка классов через веса примеров\n",
    "        if self.class_weight == 'balanced':\n",
    "            cw = compute_class_weight('balanced', classes=np.array([0, 1]), y=y)\n",
    "            self.sample_w_ = np.where(y == 1, cw[1], cw[0])\n",
    "        else:\n",
    "            self.sample_w_ = np.ones(n)\n",
    "\n",
    "        self.losses_ = []\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Перемешиваем каждую эпоху\n",
    "            idx = np.random.permutation(n)\n",
    "            Xs, ys, ws = X[idx], y[idx], self.sample_w_[idx]\n",
    "\n",
    "            for s in range(0, n, self.batch_size):\n",
    "                Xb = Xs[s : s + self.batch_size]\n",
    "                yb = ys[s : s + self.batch_size]\n",
    "                wb = ws[s : s + self.batch_size]\n",
    "\n",
    "                # Forward pass\n",
    "                y_hat = self._sigmoid(Xb @ self.weights_ + self.bias_)\n",
    "\n",
    "                # Взвешенный градиент\n",
    "                err = wb * (y_hat - yb)\n",
    "                dw  = (Xb.T @ err) / len(yb) + self.lambda_ * self.weights_\n",
    "                db  = np.mean(err)\n",
    "\n",
    "                # Обновление весов (SGD)\n",
    "                self.weights_ -= self.lr * dw\n",
    "                self.bias_    -= self.lr * db\n",
    "\n",
    "            # BCE loss на полной выборке (для мониторинга)\n",
    "            y_hat_full = self._sigmoid(X @ self.weights_ + self.bias_)\n",
    "            eps  = 1e-9\n",
    "            loss = -np.mean(\n",
    "                self.sample_w_ * (\n",
    "                    y * np.log(y_hat_full + eps) +\n",
    "                    (1 - y) * np.log(1 - y_hat_full + eps)\n",
    "                )\n",
    "            )\n",
    "            self.losses_.append(loss)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self._sigmoid(np.array(X, dtype=np.float64) @ self.weights_ + self.bias_)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "print('Класс CustomLogisticRegression определён')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных: запускаем imputer + fe из Pipeline, затем масштабируем\n",
    "imputer = MissingValueImputer().fit(X_train)\n",
    "fe      = FeatureEngineer()\n",
    "scaler  = StandardScaler()\n",
    "\n",
    "X_train_sc = scaler.fit_transform(fe.transform(imputer.transform(X_train)))\n",
    "X_val_sc   = scaler.transform(fe.transform(imputer.transform(X_val)))\n",
    "\n",
    "# Обучаем самописную LR\n",
    "custom_lr = CustomLogisticRegression(\n",
    "    lr=0.05, n_epochs=150, batch_size=64,\n",
    "    lambda_=0.01, class_weight='balanced',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "custom_lr.fit(X_train_sc, y_train)\n",
    "\n",
    "proba_custom = custom_lr.predict_proba(X_val_sc)\n",
    "f1s_custom   = [f1_score(y_val, (proba_custom >= t).astype(int)) for t in THRESHOLDS]\n",
    "f1_custom    = max(f1s_custom)\n",
    "thr_custom   = THRESHOLDS[int(np.argmax(f1s_custom))]\n",
    "\n",
    "print('=== Самописная Logistic Regression ===')\n",
    "print(f'F1-score: {f1_custom:.4f}  |  порог: {thr_custom:.2f}')\n",
    "print(classification_report(y_val, (proba_custom >= thr_custom).astype(int),\n",
    "                             target_names=['Нет дефолта', 'Дефолт']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss_curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кривая обучения самописной LR\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.plot(custom_lr.losses_, color='steelblue')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Weighted BCE Loss')\n",
    "plt.title('Кривая обучения — CustomLogisticRegression (mini-batch SGD)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full_compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговое сравнение всех моделей\n",
    "all_results = pd.DataFrame({\n",
    "    'Модель': [\n",
    "        'Random Forest (Pipeline)',\n",
    "        'Gradient Boosting (Pipeline)',\n",
    "        'Logistic Regression sklearn (Pipeline)',\n",
    "        'Logistic Regression самописная'\n",
    "    ],\n",
    "    'F1-score':          [f1_rf,  f1_gb,  f1_lr,  f1_custom],\n",
    "    'Оптимальный порог': [thr_rf, thr_gb, thr_lr, thr_custom]\n",
    "}).sort_values('F1-score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(all_results)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "colors = ['gold', 'steelblue', 'teal', 'tomato']\n",
    "bars = plt.barh(all_results['Модель'], all_results['F1-score'], color=colors)\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Целевой F1 = 0.5')\n",
    "for bar, val in zip(bars, all_results['F1-score']):\n",
    "    plt.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:.4f}', va='center', fontweight='bold')\n",
    "plt.xlabel('F1-score')\n",
    "plt.title('Итоговое сравнение всех моделей')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n=== Вывод ===')\n",
    "print(f'Лучшая модель: Random Forest (F1 = {f1_rf:.4f})')\n",
    "print(f'Самописная LR vs sklearn LR: {f1_custom:.4f} vs {f1_lr:.4f}')\n",
    "print(f'CV Random Forest: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec6",
   "metadata": {},
   "source": [
    "6. Прогноз на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инференс через Pipeline — всё в одном вызове\n",
    "proba_test  = pipe_rf.predict_proba(X_test_raw)[:, 1]\n",
    "y_test_pred = (proba_test >= thr_rf).astype(int)\n",
    "\n",
    "# Вариант 1: id + Credit Default\n",
    "pd.DataFrame({'id': range(len(y_test_pred)), 'Credit Default': y_test_pred}) \\\n",
    "  .to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Вариант 2: только Credit Default (без id)\n",
    "pd.DataFrame({'Credit Default': y_test_pred}) \\\n",
    "  .to_csv('predictions_only_target.csv', index=False)\n",
    "\n",
    "print('Прогнозы сохранены:')\n",
    "print('  predictions.csv             — id + Credit Default')\n",
    "print('  predictions_only_target.csv — только Credit Default')\n",
    "print(f'\\nВсего строк:  {len(y_test_pred)}')\n",
    "print(f'Дефолт (1):   {y_test_pred.sum()} ({y_test_pred.mean()*100:.1f}%)')\n",
    "print(f'Нет дефолта:  {(1-y_test_pred).sum()} ({(1-y_test_pred.mean())*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec7",
   "metadata": {},
   "source": [
    "7. Выводы\n",
    "\n",
    "#Результаты\n",
    "\n",
    "| Модель | F1-score |\n",
    "|--------|---------|\n",
    "| Random Forest Pipeline | **0.5331** |\n",
    "| Gradient Boosting Pipeline | 0.5228 |\n",
    "| LogisticRegression sklearn Pipeline | 0.5051 |\n",
    "| LogisticRegression самописная | 0.5043 |\n",
    "\n",
    "CV Random Forest (5-fold): **0.5230 ± 0.0138**\n",
    "\n",
    "#Ключевые выводы\n",
    "\n",
    "1. **sklearn Pipeline** — весь пайплайн (imputer → feature engineering → scaler → model) собран в единый объект. Это исключает data leakage и упрощает воспроизводство результатов.\n",
    "2. **Дисбаланс классов** (72/28) — критически важен. Без `class_weight='balanced'` F1 падает до 0.3–0.4.\n",
    "3. **Подбор порога** вместо дефолтного 0.5 дал прирост ~2–3% F1.\n",
    "4. **Random Forest** превзошёл линейные модели, уловив нелинейные зависимости.\n",
    "5. **Самописная LR** (mini-batch SGD + L2 + sample_weight) дала результат, идентичный sklearn LR — корректность алгоритма подтверждена.\n",
    "6. `Current Loan Amount = 99999999` — sentinel-значение, обязательно заменять на NaN.\n",
    "7. **Credit Score** в датасете не является стандартной FICO-шкалой (300–850). Нормировка проверена экспериментально и ухудшает качество — признак оставлен как есть."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
